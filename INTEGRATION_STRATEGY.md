# YouTube Studio Integration Strategy

**Date:** December 21, 2025  
**Version:** 1.0  
**Status:** Planning â†’ Implementation

---

## ğŸ“‹ Executive Summary

This document outlines the integration strategy for connecting three critical components:

1. **youtube-studio UI** (Frontend - Next.js app in `codecraft-labs/apps/youtube-studio`)
2. **yt-api-client** (TypeScript API client in `codecraft-labs/packages/yt-api-client`)
3. **yt-studio** (Python pipeline in workspace root)

**Goal:** Enable the UI to trigger video generation via the API client, which orchestrates the Python pipeline, while supporting reference audio uploads.

---

## ğŸ—ï¸ Current Architecture Analysis

### Component 1: youtube-studio UI (Frontend)
**Location:** `/Users/saswatapal/workspace/codecraft-labs/apps/youtube-studio`

**Capabilities:**
- âœ… Video Library View (list, filter, play, edit, delete videos)
- âœ… Create Video View (URL/description input, audio settings)
- âœ… Voice Library View (upload custom voices, manage voice profiles)
- âœ… Audio Settings (tempo, emotion, theme, volume controls)
- âœ… React Query hooks for API integration
- âœ… Real-time progress tracking via WebSocket

**Tech Stack:**
- Next.js 15, React 19
- TanStack Query for data fetching
- NextAuth for authentication
- Radix UI components
- TypeScript

**Missing:**
- âŒ Connection to actual backend API
- âŒ Reference audio upload to yt-studio pipeline
- âŒ Integration with yt-api-client package

### Component 2: yt-api-client (API Client Package)
**Location:** `/Users/saswatapal/workspace/codecraft-labs/packages/yt-api-client`

**Capabilities:**
- âœ… Type-safe API client class (`YouTubeStudioAPI`)
- âœ… Zod schema validation
- âœ… Video CRUD operations (create, list, get, update, delete, regenerate, download)
- âœ… Voice profile management (list, get, create, delete)
- âœ… WebSocket progress subscription
- âœ… Authentication token support

**Current State:**
- âœ… Fully implemented TypeScript client
- âœ… Exported from package for consumption
- âœ… Type definitions aligned with backend

**Missing:**
- âŒ Not connected to actual backend yet (expects backend at localhost:8000)
- âŒ No integration tests

### Component 3: yt-studio (Python Pipeline)
**Location:** `/Users/saswatapal/workspace/yt-studio`

**Capabilities:**
- âœ… Complete video generation pipeline (script â†’ audio â†’ slides â†’ video)
- âœ… ChatterBox TTS voice cloning with reference audio
- âœ… AI-powered slide generation (Ollama) or parser-based
- âœ… FFmpeg video assembly
- âœ… FastAPI backend (`api/server.py`)
- âœ… Database models for videos and voices
- âœ… Progress tracking with WebSocket
- âœ… Background task processing

**Tech Stack:**
- Python 3.10+
- FastAPI for REST API
- SQLAlchemy for database
- ChatterBox TTS for voiceover
- FFmpeg for video encoding
- Ollama for AI features

**Current State:**
- âœ… FastAPI routes defined (`/api/videos`, `/api/voices`, `/api/progress`)
- âœ… Service layer for business logic
- âœ… Pipeline orchestration via `yt-pipeline.py`
- âœ… Reference audio support in config

**Missing:**
- âŒ Reference audio upload endpoint not implemented
- âŒ Integration with frontend auth
- âŒ Proper database persistence (currently in-memory)

---

## ğŸ¯ Integration Objectives

### Phase 1: Backend Setup âœ… (Already Done)
- [x] FastAPI server with CORS
- [x] Video routes (`/api/videos/*`)
- [x] Voice routes (`/api/voices/*`)
- [x] Progress WebSocket (`/api/progress/:id`)

### Phase 2: Connect UI to API Client âš¡ (Current Focus)
- [ ] Wire up `useAPIClient` hook to use `@ccl/yt-api-client`
- [ ] Configure API base URL from environment
- [ ] Test video creation flow
- [ ] Test voice upload flow
- [ ] Implement progress tracking UI

### Phase 3: Reference Audio Upload ğŸ™ï¸
- [ ] Add reference audio upload endpoint to backend
- [ ] Update voice service to handle reference audio
- [ ] Create reference audio UI component
- [ ] Link reference audio to video generation

### Phase 4: Pipeline Integration ğŸ”§
- [ ] Connect backend video service to `yt-pipeline.py`
- [ ] Implement background job queue
- [ ] Add progress broadcasting via WebSocket
- [ ] Handle pipeline errors and retries

### Phase 5: Database & Persistence ğŸ’¾
- [ ] Replace in-memory storage with SQLite/PostgreSQL
- [ ] Implement Alembic migrations
- [ ] Add file storage for videos/audio
- [ ] User authentication integration

---

## ğŸ”Œ Integration Points

### 1. Frontend â†’ API Client
**File:** `codecraft-labs/apps/youtube-studio/src/hooks/use-api.ts`

**Current Implementation:**
```typescript
const apiClient = new YouTubeStudioAPI({
  baseUrl: process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000',
  getAccessToken: async () => session?.accessToken || null,
});
```

**Status:** âœ… Already implemented, needs backend URL configuration

**Action Items:**
- Set `NEXT_PUBLIC_API_URL` in `.env.local`
- Verify auth token flow
- Test API calls

### 2. API Client â†’ Backend API
**Client:** `codecraft-labs/packages/yt-api-client/src/client.ts`  
**Server:** `yt-studio/api/server.py`

**Endpoints Mapping:**
| Client Method | Backend Route | Status |
|--------------|---------------|--------|
| `videos.create()` | `POST /api/videos` | âœ… Implemented |
| `videos.list()` | `GET /api/videos` | âœ… Implemented |
| `videos.get(id)` | `GET /api/videos/:id` | âœ… Implemented |
| `videos.update(id)` | `PATCH /api/videos/:id` | âœ… Implemented |
| `videos.delete(id)` | `DELETE /api/videos/:id` | âœ… Implemented |
| `videos.regenerate(id)` | `POST /api/videos/:id/regenerate` | âœ… Implemented |
| `videos.download(id)` | `GET /api/videos/:id/download` | âœ… Implemented |
| `voices.list()` | `GET /api/voices` | âœ… Implemented |
| `voices.create()` | `POST /api/voices` | âœ… Implemented |
| `voices.delete(id)` | `DELETE /api/voices/:id` | âœ… Implemented |
| `subscribeToProgress()` | `WS /api/progress/:id` | âœ… Implemented |

**Action Items:**
- Test all endpoints
- Add error handling
- Implement retry logic

### 3. Backend API â†’ Python Pipeline
**Service:** `yt-studio/api/services/video_service.py`  
**Pipeline:** `yt-studio/yt-pipeline.py`

**Current Gap:** Backend service needs to invoke pipeline

**Proposed Implementation:**
```python
async def generate_video(self, video_id: str):
    """Background task to generate video using pipeline"""
    video = await self.get_video(video_id)
    if not video:
        return
    
    try:
        # Update status
        video.status = VideoStatus.PROCESSING
        video.current_stage = GenerationStage.EXTRACTING_CONTENT
        await self.emit_progress(video_id, 0, "Starting generation...")
        
        # Write script to file
        script_path = f"outputs/scripts/{video_id}.txt"
        with open(script_path, 'w') as f:
            f.write(video.script_content)
        
        # Run pipeline
        result = subprocess.run(
            ["python3", "yt-pipeline.py", "run", video_id, "--profile", video.profile],
            capture_output=True,
            text=True,
            cwd="/Users/saswatapal/workspace/yt-studio"
        )
        
        if result.returncode == 0:
            video.status = VideoStatus.READY
            video.video_url = f"outputs/videos/{video_id}.mp4"
            await self.emit_progress(video_id, 100, "Video ready!")
        else:
            video.status = VideoStatus.ERROR
            video.error = result.stderr
            await self.emit_progress(video_id, 0, "Generation failed")
            
    except Exception as e:
        video.status = VideoStatus.ERROR
        video.error = str(e)
        logger.error(f"Pipeline error: {e}")
```

**Action Items:**
- Implement pipeline invocation in video service
- Add progress tracking hooks
- Handle voice profile reference audio
- Implement error recovery

### 4. Reference Audio Upload Flow

**Current State:**
- âœ… UI has voice upload component
- âœ… Voice API endpoint exists
- âŒ Backend doesn't connect to pipeline reference audio

**Proposed Flow:**
```
User uploads audio file (Voice Library UI)
    â†“
Frontend sends FormData to API client
    â†“
yt-api-client POSTs to /api/voices
    â†“
Backend saves audio to yt-studio/outputs/audio/references/{voice_id}.wav
    â†“
Updates config.yaml or passes to pipeline as parameter
    â†“
Pipeline uses reference audio for voice cloning
```

**Implementation Plan:**
1. Update voice service to save uploaded audio to correct location
2. Add reference audio parameter to video generation
3. Modify pipeline to accept voice profile ID
4. Use custom reference audio instead of default

---

## ğŸ“ File Structure After Integration

```
codecraft-labs/
â”œâ”€â”€ apps/
â”‚   â””â”€â”€ youtube-studio/          # Next.js Frontend
â”‚       â”œâ”€â”€ .env.local           # API_URL=http://localhost:8000
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ components/      # UI components âœ…
â”‚       â”‚   â”œâ”€â”€ hooks/
â”‚       â”‚   â”‚   â””â”€â”€ use-api.ts   # Uses @ccl/yt-api-client âœ…
â”‚       â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ package.json         # Depends on @ccl/yt-api-client âœ…
â”‚
â””â”€â”€ packages/
    â””â”€â”€ yt-api-client/           # TypeScript API Client
        â”œâ”€â”€ src/
        â”‚   â”œâ”€â”€ client.ts        # API methods âœ…
        â”‚   â””â”€â”€ types.ts         # Zod schemas âœ…
        â””â”€â”€ package.json         # Exports client âœ…

workspace/yt-studio/             # Python Pipeline Backend
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ server.py               # FastAPI app âœ…
â”‚   â”œâ”€â”€ models/                 # Data models âœ…
â”‚   â”œâ”€â”€ routes/                 # API endpoints âœ…
â”‚   â”‚   â”œâ”€â”€ videos.py          # Video CRUD âœ…
â”‚   â”‚   â”œâ”€â”€ voices.py          # Voice CRUD âœ…
â”‚   â”‚   â””â”€â”€ progress.py        # WebSocket âœ…
â”‚   â””â”€â”€ services/              # Business logic
â”‚       â”œâ”€â”€ video_service.py   # Needs pipeline integration âš¡
â”‚       â””â”€â”€ voice_service.py   # Needs file storage âš¡
â”‚
â”œâ”€â”€ yt-pipeline.py             # Pipeline orchestrator âœ…
â”œâ”€â”€ config.yaml                # Configuration âœ…
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ scripts/               # Generated scripts
â”‚   â”œâ”€â”€ audio/                 # Generated audio
â”‚   â”‚   â””â”€â”€ references/        # User uploaded voices (NEW)
â”‚   â”œâ”€â”€ slides/                # Generated slides
â”‚   â””â”€â”€ videos/                # Final videos
â””â”€â”€ voiceover/                 # Voice cloning engine âœ…
```

---

## ğŸš€ Implementation Roadmap

### Week 1: Core Integration
**Days 1-2:** Backend-Pipeline Connection
- [ ] Implement pipeline invocation in video service
- [ ] Add progress tracking
- [ ] Test video generation end-to-end

**Days 3-4:** Reference Audio Upload
- [ ] Create reference audio storage directory
- [ ] Update voice service to save files
- [ ] Link voice profiles to video generation
- [ ] Test voice cloning with custom audio

**Day 5:** Testing & Bug Fixes
- [ ] Integration testing
- [ ] Error handling
- [ ] Performance optimization

### Week 2: Polish & Deploy
**Days 1-2:** Database Migration
- [ ] Set up PostgreSQL
- [ ] Create migrations
- [ ] Migrate data

**Days 3-4:** Production Setup
- [ ] Docker containers
- [ ] Environment variables
- [ ] Deployment scripts

**Day 5:** Documentation & Handoff
- [ ] API documentation
- [ ] User guide
- [ ] Admin guide

---

## ğŸ”§ Technical Decisions

### 1. API Base URL Configuration
**Decision:** Use environment variables for flexibility
```env
# codecraft-labs/apps/youtube-studio/.env.local
NEXT_PUBLIC_API_URL=http://localhost:8000

# Production
NEXT_PUBLIC_API_URL=https://api.yourstudio.com
```

### 2. Reference Audio Storage
**Decision:** Store in yt-studio pipeline directory
```
yt-studio/outputs/audio/references/
â”œâ”€â”€ {voice_id}_original.wav    # Original upload
â””â”€â”€ {voice_id}_optimized.wav   # Processed for TTS
```

### 3. Pipeline Invocation Method
**Decision:** Subprocess call to Python CLI
- **Pros:** Uses existing battle-tested pipeline
- **Cons:** Slower than direct Python import
- **Alternative:** Import pipeline as library (future optimization)

### 4. Progress Tracking
**Decision:** Dual approach
- **Coarse:** Backend emits major stage updates
- **Fine:** Pipeline logs detailed progress
- **Transport:** WebSocket for real-time updates

### 5. Authentication
**Decision:** NextAuth â†’ JWT â†’ FastAPI
```typescript
// Frontend
session.accessToken â†’ API client

// Backend
@app.middleware("http")
async def auth_middleware(request, call_next):
    token = request.headers.get("Authorization")
    # Verify JWT
```

---

## ğŸ“Š Success Metrics

### Functional
- [ ] User can create video from UI
- [ ] Video generation completes successfully
- [ ] Progress updates in real-time
- [ ] Custom voices work correctly
- [ ] Videos are downloadable

### Performance
- [ ] Video generation: < 15 minutes (fast mode)
- [ ] API response time: < 200ms
- [ ] WebSocket latency: < 100ms
- [ ] File upload: < 30 seconds

### Quality
- [ ] Error handling covers edge cases
- [ ] Logs are comprehensive
- [ ] TypeScript types are accurate
- [ ] API documentation is complete

---

## ğŸ”’ Security Considerations

1. **File Upload Validation**
   - Limit file size (10MB for audio)
   - Validate MIME types
   - Scan for malware

2. **Authentication**
   - JWT token verification
   - User isolation (can't access others' videos)
   - Rate limiting on API endpoints

3. **File Access**
   - Serve files through API (not direct filesystem access)
   - Validate file paths to prevent traversal
   - Set proper permissions

---

## ğŸ“ Next Steps

### Immediate Actions (Today)
1. âœ… Create this strategy document
2. âš¡ Set up backend API environment
3. âš¡ Configure frontend API URL
4. âš¡ Test first video creation flow

### This Week
1. Implement pipeline integration
2. Add reference audio upload
3. Test end-to-end flow
4. Fix bugs

### Next Week
1. Database migration
2. Production deployment
3. Documentation
4. User testing

---

## ğŸ¤ Team Communication

### Questions to Resolve
1. Database choice: PostgreSQL vs SQLite?
2. File storage: Local vs S3/Cloud?
3. Deployment target: VPS vs Vercel/Railway?
4. Authentication: Email/password vs OAuth?

### Blockers
- None currently

### Risks
1. **Pipeline performance:** ChatterBox TTS is slow (~3-4 min/chunk)
   - **Mitigation:** Use queue system, show accurate time estimates
2. **File storage:** Large video files
   - **Mitigation:** Implement cleanup policy, use cloud storage
3. **Concurrent generations:** Resource contention
   - **Mitigation:** Limit concurrent jobs, add queue

---

**Document Owner:** GitHub Copilot  
**Last Updated:** December 21, 2025  
**Next Review:** After Phase 2 completion
